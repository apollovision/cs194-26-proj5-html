<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-size: 16px;
    font-weight: 300;
    font-family: 'Questrial', sans-serif;
    color: #121212;
  }
  h1 {
    font-size: 22px;
    font-family: 'Press Start 2P', cursive;
    color: #000000;
    margin-top: 0px;
    margin-bottom: 0px;
  }
  h2, h3 {
    font-family: 'Questrial', sans-serif;
    src: URL('fonts/Questrial-Regular.ttf');
    color: #121212;
  }
  h5 {
    text-align: middle;
    font-family: 'Questrial', sans-serif;
    src: URL('fonts/Questrial-Regular.ttf');
    font-size: 16px;
    font-weight: 300;
    margin-top: 15px;
    margin-bottom: 15px;
    margin-right: 200px;
    margin-left: 200px;
  }
  h6 {
    font-family: 'Questrial', sans-serif;
    src: URL('fonts/Questrial-Regular.ttf');
    font-size: 16px;
    font-weight: 300;
    margin-top: 15px;
    margin-bottom: 15px;
    margin-right: 0px;
    margin-left: 0px;
  }
  figcaption {
    text-align: middle;
    font-family: 'Questrial', sans-serif;
    src: URL('fonts/Questrial-Regular.ttf');
    font-size: 12px;
    font-weight: 300;
    margin-top: 0px;
    margin-bottom: 15px;
  }
  p {
    text-align: justify;
    -moz-text-align-last: center;
    text-align-last: center;
    font-family: 'Questrial', sans-serif;
    src: URL('fonts/Questrial-Regular.ttf');
    font-size: 16px;
    font-weight: 300;
    margin-top: 15px;
    margin-bottom: 15px;
    margin-right: 200px;
    margin-left: 200px;
  }
  h4 {
    font-family: 'Pinyon Script', cursive;
    font-size: 56px;
    color: #000000;
    margin-top: 0px;
    margin-bottom: 0px;
  }

</style>
<title>Autostitching and Image Mosaics, Checkpoint</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
</head>

<body>
<p id="top">
</p>
<br><br><br>
<h4 align="middle" id="Part 0">Autostitching <br> and <br> Image Mosaics <br></h4>
<!--<div align="middle">-->
  <!--<table style="width=100%">-->
    <!--<tr>-->
    <!--<td>-->
      <!--<img src="images/title.png" class="thumbnail" align="middle" width="350px"/>-->
    <!--</td>-->
    <!--<td>-->
  <!--</table>-->
<!--</div>-->
<!--<h4 align="middle">with <br>Neural Networks</h4>-->

<!--<br>-->
<h3 align="middle"><span style="color:white">dream and make the new reality with us</span></h3>
<h2 align="middle"><span style="color:white">xr.berkeley.edu</span></h2>
<!--<br>-->



<h2 align="middle">Table of Contents</h2>
<h2 align="middle">—</h2>
<a href="#Part 1"><h6 align="middle">1. Perspective Warp</h6></a>
<a href="#Part 2"><h6 align="middle">2. Harris Corner Detector and ANMS</h6></a>
<a href="#Part 3"><h6 align="middle">3. Extracting and Matching Feature Descriptors</h6></a>
<a href="#Part 4"><h6 align="middle">4. Image Mosaics</h6></a>
<a href="#Part 5"><h6 align="middle">5. Cylindrical Mapping and 360° Panorama</h6></a>
<a href="#Part 6"><h6 align="middle">6. Panorama Recognition</h6></a>
<br><br><br><br><br><br><br><br>

<a href="#Part 0"><h2 align="middle"><b>↑</b></h2></a>
<h3 align="middle" id="Part 1">1. Perspective Warp</h3>
<a href="#Part 2"><h2 align="middle"><b>↓</b></h2></a>
<br>

<p>
The homography is a very versatile operation. Thanks to it, I saw what Picasso saw, and
saw Aristotle seemingly say something important to Plato.
</p>
<br><br>

<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/nature_morte.jpg" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"> <br><br> Nature morte au compotier, Picasso (1915)</figcaption>
    </td>
    <td>
      <img src="images/school_of_athens.jpg" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"> <br><br> The School of Athens, Rafael (1511)</figcaption>
    </td>
    </tr>
    <tr>
    <td>
      <img src="images/rect1.png" class="thumbnail" align="middle" width="300px"/>
    </td>
    <td>
      <img src="images/rect2.png" class="thumbnail" align="middle" width="300px"/>
    </td>
    </tr>
  </table>
</div>
<br><br><br><br>
<br><br><br><br>

<a href="#Part 1"><h2 align="middle"><b>↑</b></h2></a>
<h3 align="middle" id="Part 2">2. Harris Corner Detector and ANMS</h3>
<a href="#Part 3"><h2 align="middle"><b>↓</b></h2></a>
<br>

<p>
I find it somewhat funny that the first recursive function I wrote after a while
was one that implemented Adaptive Non-Maximal Supression (ANMS). But when I think about it,
this only makes sense:
after a nice semester of relying on NumPy, I developped somewhat of an <i>aversion</i>
to <i>for</i> loops. That said, ANMS was also the slowest function I wrote since a while.
Having to search through all local maxima, without a NumPy magic trick to save the day,
one thing is for sure, the process is going to be slow. As such, I somewhat
deviated from <a href="https://inst.eecs.berkeley.edu/~cs194-26/fa20/hw/proj5/Papers/MOPS.pdf">Brown et al. (2005)</a>, by introducing an additional parameter to the ANMS, namely "greediness". The higher
the greediness, the fewer points are checked for neighbors within radius length. Practically this
worked well for testing, but for the final results, I decided to not cut corners.
</p>
<p>
Otherwise,
I set the <i>c_robust</i> parameter to 0.9, as Brown et al. suggest, and begin searching from
a radius of 0. The following figures demonstrate the results of the Harris Corner detector,
and how the points can be "better spread" by using ANMS. Notice that when <i>c_robust</i> is very small, as in the last figure, the procedure may not always lead to the desired number of points.
This is because the distribution of keypoints may be such that many points within a really large radius (that practically spans the totality of the image), are above a certain intensity, and therefore never fail the <i>c_robust</i> test. The goal for the last figure was to reach 112 points, but with a <i>c_robust</i> of 0.3, the process halted at 204 points. This means that 204 points had all intensities above 0.3 times the intensity of the maximum, and therefore could not be eliminated. On the other hand, setting <i>c_robust</i> above 1 is also problematic, given that it can potentially eliminate points with greater intensities (and therefore more likely to be features) than others within a given radius. Notice this difference in the figures below where <i>c_robust</i> is set to 1.5.
</p>
<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/harris_0.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Harris Corner Detection, >2000 points</figcaption>
    </td>
    <td>
      <img src="images/harris_1.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Harris Corner Detection, >2000 points</figcaption>
    </td>
    </tr>
  </table>
</div>

<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/ANMS/c_robust_255_15.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 1.5, 255 points</figcaption>
    </td>
    <td>
      <img src="images/ANMS/c_robust_255_09.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 0.9, 255 points</figcaption>
    </td>
    <td>
      <img src="images/ANMS/c_robust_255_03.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 0.3, 255 points</figcaption>
    </td>
    </tr>
    <tr>
    <td>
      <img src="images/ANMS/c_robust_112_15.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 1.5, 112 points</figcaption>
    </td>
    <td>
      <img src="images/ANMS/c_robust_112_09.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 0.9, 112 points</figcaption>
    </td>
    <td>
      <img src="images/ANMS/c_robust_112_03.png" class="thumbnail" align="middle" width="300px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> c_robust = 0.3, 204 points</figcaption>
    </td>
    </tr>
  </table>
</div>
<br><br><br><br>
<br><br><br><br>

<a href="#Part 2"><h2 align="middle"><b>↑</b></h2></a>
<h3 align="middle" id="Part 3">3. Extracting and Matching Feature Descriptors</h3>
<a href="#Part 4"><h2 align="middle"><b>↓</b></h2></a>
<br>
<p>
Talk as much as you want about Aristotle and Plato, but for this project I owe my money to Pythagoras.
</p>
<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/descriptors/1.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/3.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/18.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/23.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    </tr>
    <tr>
    <td>
      <img src="images/descriptors/25.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/31.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/38.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    <td>
      <img src="images/descriptors/40.png" class="thumbnail" align="middle" width="200px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Randomly Sampled Feature Vector</figcaption>
    </td>
    </tr>
  </table>
</div>
<p>
<br>
I can't remember how many times I used the SSD for this part. <br> For the threshold against which to evaluate 1-NN/2-NN (aka. Lowe's ratio), I chose 0.4, as this seemed to be the inflection point after which comparatively more outliers will be selected than inliers.
</p>
<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/matches_8.png" class="thumbnail" align="middle" width="600px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Feature matching with 8 points.</figcaption>
    </td>
    </tr>
    <tr>
    <td>
      <img src="images/matches_313.png" class="thumbnail" align="middle" width="600px"/>
      <br>
      <figcaption align="middle"><b>—</b> <br> Feature matching with 313 points.</figcaption>
    </td>
    </tr>
  </table>
</div>
<br><br><br><br>
<br><br><br><br>

<a href="#Part 3"><h2 align="middle"><b>↑</b></h2></a>
<h3 align="middle" id="Part 4">4. Image Mosaics</h3>
<a href="#Part 5"><h2 align="middle"><b>↓</b></h2></a>
<br>
<p>
</p>


<p>
I really liked this project, because it required both geometric thinking (how to stitch the images together) as well a strong perceptual and aesthetic intuition (how to make the stitched images look good together). I learned the hard way that, unless the images have very similar exposure, even advanced blending techniques will fail at making them appear uniform. That said, the versatility and effectiveness of the homography impressed me. I can now easily see how a homography would be used in other problems of computer vision, such 3D reconstruction. Finally, the most important thing I learned (but did not implement yet), regards transformations in non-Euclidian space. For Part B, I plan on making a 360° panorama, by mapping the homography in spherical space.
</p>
<br><br>
<br><br>


<a href="#Part 0"><h2 align="middle"><b>⇈</b></h2></a>
<br>

<h6 align="middle"> I accidentally passed in the points of a set of planarly-mapped images<br>
    alongside cylindrically-mapped images to my stitching algorithm.<br>
    <br>What followed had no precedent.</h6>
<br>
<h2 align="middle"> Randomness </h2>
<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/random_noise.png" class="thumbnail" align="middle" width="400px"/>
    </td>
    </tr>
  </table>
</div>
<br>
<hr>
<h4 align="middle">♡☮</h4>
<hr>
<h3 align="middle">CS 194-26: Computer Vision and Computational Photography (Fall 2020)</h3>
<div align="middle">
  <table style="width=100%">
    <tr>
    <td>
      <img src="images/Signature.png" class="thumbnail" align="middle" width="150px"/>
    </td>
    </tr>
  </table>
</div>

</body>
</html>
